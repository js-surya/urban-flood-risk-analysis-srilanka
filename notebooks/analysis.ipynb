{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Urban Flood Vulnerability Assessment - Colombo District, Sri Lanka\n",
                "\n",
                "**Assignment 2 - Scientific Programming for Geospatial Sciences**\n",
                "\n",
                "**Authors:** Surya Jamuna Rani Subramaniyan (S3664414) & Sachin Ravi (S3563545)\n",
                "\n",
                "---\n",
                "\n",
                "## Contents\n",
                "\n",
                "0. **Setup & Data Download** - Automated data acquisition\n",
                "1. **Data Loading** - Load and preprocess datasets\n",
                "2. **NumPy Array Operations** - Raster processing\n",
                "3. **PyTorch Tensor Operations** - GPU-aware processing with performance comparison\n",
                "4. **Vector Processing** - GeoPandas/Shapely operations (3+)\n",
                "5. **Xarray Data Cubes** - Multi-temporal analysis\n",
                "6. **Raster-Vector Integration** - Bidirectional operations\n",
                "7. **Visualization** - Maps and dashboard\n",
                "\n",
                "---\n",
                "\n",
                "**Study Area:** Colombo District, Sri Lanka  \n",
                "**Bounding Box:** 79.82¬∞E - 80.22¬∞E, 6.75¬∞N - 7.05¬∞N"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. Setup & Data Download\n",
                "\n",
                "Run this section once to download all required datasets automatically.  \n",
                "**No API keys required!**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# imports\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import xarray as xr\n",
                "import geopandas as gpd\n",
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "import requests\n",
                "import json\n",
                "import zipfile\n",
                "import gzip\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# our modules\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "from src import data_loading, raster_analysis, tensor_operations, vector_analysis, integration, visualization\n",
                "\n",
                "print(\"‚úÖ All imports successful!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Study area configuration\n",
                "COLOMBO_BBOX = {\n",
                "    'west': 79.82,\n",
                "    'east': 80.22,\n",
                "    'south': 6.75,\n",
                "    'north': 7.05\n",
                "}\n",
                "\n",
                "# Paths\n",
                "DATA_DIR = Path('../data')\n",
                "RAW_DIR = DATA_DIR / 'raw'\n",
                "PROCESSED_DIR = DATA_DIR / 'processed'\n",
                "OUTPUT_DIR = Path('../outputs')\n",
                "\n",
                "# Create directories\n",
                "for d in [RAW_DIR / 'chirps', RAW_DIR / 'dem', RAW_DIR / 'admin', \n",
                "          RAW_DIR / 'buildings', PROCESSED_DIR, OUTPUT_DIR]:\n",
                "    d.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"üìÅ Directories created:\")\n",
                "print(f\"   - {RAW_DIR}\")\n",
                "print(f\"   - {PROCESSED_DIR}\")\n",
                "print(f\"   - {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper function for downloads\n",
                "def download_file(url, output_path, timeout=60):\n",
                "    \"\"\"Download a file with progress indication.\"\"\"\n",
                "    if output_path.exists():\n",
                "        print(f\"  ‚úÖ Already exists: {output_path.name}\")\n",
                "        return True\n",
                "    \n",
                "    try:\n",
                "        print(f\"  ‚¨áÔ∏è Downloading: {output_path.name}\")\n",
                "        response = requests.get(url, stream=True, timeout=timeout)\n",
                "        response.raise_for_status()\n",
                "        \n",
                "        with open(output_path, 'wb') as f:\n",
                "            for chunk in response.iter_content(chunk_size=8192):\n",
                "                f.write(chunk)\n",
                "        \n",
                "        print(f\"  ‚úÖ Saved: {output_path.name}\")\n",
                "        return True\n",
                "    except Exception as e:\n",
                "        print(f\"  ‚ùå Error: {e}\")\n",
                "        return False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 0.1 Download SRTM DEM from AWS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download SRTM tiles from AWS Open Data (no API key needed!)\n",
                "print(\"üì° Downloading SRTM DEM from AWS...\")\n",
                "\n",
                "# Get required tiles for Colombo\n",
                "srtm_tiles = ['N06E079', 'N06E080', 'N07E079', 'N07E080']\n",
                "base_url = \"https://elevation-tiles-prod.s3.amazonaws.com/skadi\"\n",
                "\n",
                "dem_files = []\n",
                "for tile in srtm_tiles:\n",
                "    lat_dir = tile[:3]\n",
                "    filename = f\"{tile}.hgt.gz\"\n",
                "    url = f\"{base_url}/{lat_dir}/{filename}\"\n",
                "    output_path = RAW_DIR / 'dem' / filename\n",
                "    \n",
                "    if download_file(url, output_path, timeout=120):\n",
                "        dem_files.append(output_path)\n",
                "\n",
                "print(f\"\\n‚úÖ Downloaded {len(dem_files)} DEM tiles\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 0.2 Download Administrative Boundaries from OSM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download Colombo District boundary using Overpass API\n",
                "print(\"üì° Downloading admin boundaries from OpenStreetMap...\")\n",
                "\n",
                "admin_path = RAW_DIR / 'admin' / 'colombo_boundary.json'\n",
                "\n",
                "if not admin_path.exists():\n",
                "    overpass_url = \"https://overpass-api.de/api/interpreter\"\n",
                "    \n",
                "    # Query for Colombo District and its subdivisions\n",
                "    query = f\"\"\"\n",
                "    [out:json][timeout:120];\n",
                "    (\n",
                "      relation[\"name\"~\"Colombo\"][\"admin_level\"~\"5|6|7\"]\n",
                "        ({COLOMBO_BBOX['south']},{COLOMBO_BBOX['west']},{COLOMBO_BBOX['north']},{COLOMBO_BBOX['east']});\n",
                "    );\n",
                "    out geom;\n",
                "    \"\"\"\n",
                "    \n",
                "    try:\n",
                "        response = requests.post(overpass_url, data={'data': query}, timeout=180)\n",
                "        response.raise_for_status()\n",
                "        data = response.json()\n",
                "        \n",
                "        with open(admin_path, 'w') as f:\n",
                "            json.dump(data, f)\n",
                "        \n",
                "        print(f\"  ‚úÖ Saved: {admin_path.name}\")\n",
                "        print(f\"  Found {len(data.get('elements', []))} boundary elements\")\n",
                "    except Exception as e:\n",
                "        print(f\"  ‚ùå Error: {e}\")\n",
                "else:\n",
                "    print(f\"  ‚úÖ Already exists: {admin_path.name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 0.3 Download CHIRPS Rainfall Data\n",
                "\n",
                "‚ö†Ô∏è **Note:** CHIRPS files are large (~2GB per year). For testing, we'll use a sample."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHIRPS download - for demo we'll use sample data\n",
                "# Uncomment below to download actual CHIRPS (WARNING: ~2GB per year)\n",
                "\n",
                "print(\"üì° CHIRPS Rainfall Data\")\n",
                "print(\"\")\n",
                "print(\"For full analysis, download CHIRPS data manually:\")\n",
                "print(\"  URL: https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_daily/netcdf/p05/\")\n",
                "print(\"  File: chirps-v2.0.2023.days_p05.nc (~2GB)\")\n",
                "print(\"  Save to: data/raw/chirps/\")\n",
                "print(\"\")\n",
                "print(\"For this demo, we'll generate sample rainfall data.\")\n",
                "\n",
                "# To download automatically (uncomment if needed):\n",
                "# chirps_url = \"https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_daily/netcdf/p05/chirps-v2.0.2023.days_p05.nc\"\n",
                "# chirps_path = RAW_DIR / 'chirps' / 'chirps-v2.0.2023.days_p05.nc'\n",
                "# download_file(chirps_url, chirps_path, timeout=3600)  # may take a while!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 0.4 Download Buildings (Optional)\n",
                "\n",
                "Buildings can come from Google Open Buildings or OSM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download OSM buildings (optional - can be slow for urban areas)\n",
                "print(\"üì° Building Footprints\")\n",
                "print(\"\")\n",
                "print(\"Options:\")\n",
                "print(\"  1. Google Open Buildings: https://sites.research.google/open-buildings/\")\n",
                "print(\"  2. OSM buildings via Overpass (can be slow)\")\n",
                "print(\"\")\n",
                "print(\"For this demo, we'll generate sample building data.\")\n",
                "\n",
                "# To download OSM buildings (uncomment if needed - may take 5-10 minutes):\n",
                "# buildings_query = f\"\"\"\n",
                "# [out:json][timeout:300];\n",
                "# (way[\"building\"]({COLOMBO_BBOX['south']},{COLOMBO_BBOX['west']},{COLOMBO_BBOX['north']},{COLOMBO_BBOX['east']}););\n",
                "# out geom;\n",
                "# \"\"\"\n",
                "# response = requests.post(\"https://overpass-api.de/api/interpreter\", data={'data': buildings_query}, timeout=600)\n",
                "# with open(RAW_DIR / 'buildings' / 'osm_buildings.json', 'w') as f:\n",
                "#     json.dump(response.json(), f)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 0.5 Data Status Check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check what data we have\n",
                "print(\"üìä DATA STATUS\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# DEM\n",
                "dem_files_found = list((RAW_DIR / 'dem').glob('*.hgt.gz'))\n",
                "print(f\"DEM tiles:      {'‚úÖ ' + str(len(dem_files_found)) + ' files' if dem_files_found else '‚ùå Not found'}\")\n",
                "\n",
                "# Admin boundaries\n",
                "admin_files = list((RAW_DIR / 'admin').glob('*.json'))\n",
                "print(f\"Admin boundary: {'‚úÖ Found' if admin_files else '‚ùå Not found'}\")\n",
                "\n",
                "# CHIRPS\n",
                "chirps_files = list((RAW_DIR / 'chirps').glob('*.nc'))\n",
                "print(f\"CHIRPS data:    {'‚úÖ Found' if chirps_files else '‚ö†Ô∏è Using sample data'}\")\n",
                "\n",
                "# Buildings\n",
                "building_files = list((RAW_DIR / 'buildings').glob('*'))\n",
                "print(f\"Buildings:      {'‚úÖ Found' if building_files else '‚ö†Ô∏è Using sample data'}\")\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"\\nüöÄ Ready to proceed with analysis!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 1. Data Loading\n",
                "\n",
                "Load the required datasets for analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For this demo, we create sample data\n",
                "# When you have real data, use data_loading module functions\n",
                "\n",
                "print(\"üìä Creating sample datasets for demonstration...\")\n",
                "\n",
                "# Sample rainfall data (simulating CHIRPS)\n",
                "np.random.seed(42)\n",
                "times = pd.date_range('2023-01-01', periods=365, freq='D')\n",
                "lats = np.linspace(COLOMBO_BBOX['south'], COLOMBO_BBOX['north'], 50)\n",
                "lons = np.linspace(COLOMBO_BBOX['west'], COLOMBO_BBOX['east'], 50)\n",
                "\n",
                "# Create realistic rainfall patterns (monsoon effect)\n",
                "rainfall_data = np.random.exponential(scale=15, size=(365, 50, 50))\n",
                "# Add monsoon peak (May-September)\n",
                "rainfall_data[120:270] *= 2.5\n",
                "\n",
                "rainfall_cube = xr.DataArray(\n",
                "    data=rainfall_data,\n",
                "    dims=['time', 'latitude', 'longitude'],\n",
                "    coords={'time': times, 'latitude': lats, 'longitude': lons},\n",
                "    name='precipitation'\n",
                ")\n",
                "\n",
                "print(f\"‚úÖ Rainfall data: {rainfall_cube.shape}\")\n",
                "print(f\"   Time range: {rainfall_cube.time.min().values} to {rainfall_cube.time.max().values}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample elevation data (simulating DEM)\n",
                "np.random.seed(42)\n",
                "# Colombo is coastal - elevation increases inland (east)\n",
                "x = np.linspace(0, 1, 50)\n",
                "y = np.linspace(0, 1, 50)\n",
                "X, Y = np.meshgrid(x, y)\n",
                "elevation_data = (X * 50 + np.random.normal(0, 5, (50, 50))).clip(0, 100)  # 0-100m\n",
                "\n",
                "elevation = xr.DataArray(\n",
                "    data=elevation_data,\n",
                "    dims=['latitude', 'longitude'],\n",
                "    coords={'latitude': lats, 'longitude': lons},\n",
                "    name='elevation'\n",
                ")\n",
                "\n",
                "print(f\"‚úÖ Elevation data: {elevation.shape}\")\n",
                "print(f\"   Range: {elevation.min().values:.1f}m - {elevation.max().values:.1f}m\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample admin boundaries and buildings\n",
                "from shapely.geometry import box, Point\n",
                "\n",
                "# Create Colombo sub-districts (Divisional Secretariats)\n",
                "ds_names = ['Colombo', 'Thimbirigasyaya', 'Dehiwala', 'Moratuwa', 'Sri Jayawardenepura Kotte']\n",
                "\n",
                "admin_boundaries = gpd.GeoDataFrame({\n",
                "    'ds_id': [f'DS{i+1:02d}' for i in range(5)],\n",
                "    'ds_name': ds_names,\n",
                "    'geometry': [\n",
                "        box(79.82, 6.90, 79.90, 7.00),\n",
                "        box(79.90, 6.90, 79.98, 7.00),\n",
                "        box(79.82, 6.82, 79.90, 6.90),\n",
                "        box(79.82, 6.75, 79.90, 6.82),\n",
                "        box(79.98, 6.90, 80.10, 7.00)\n",
                "    ]\n",
                "}, crs='EPSG:4326')\n",
                "\n",
                "print(f\"‚úÖ Admin boundaries: {len(admin_boundaries)} divisions\")\n",
                "print(admin_boundaries[['ds_id', 'ds_name']])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample buildings (more in urban core)\n",
                "np.random.seed(42)\n",
                "\n",
                "# Generate more buildings in western (coastal/urban) areas\n",
                "n_buildings = 500\n",
                "building_lons = np.random.beta(2, 5, n_buildings) * (COLOMBO_BBOX['east'] - COLOMBO_BBOX['west']) + COLOMBO_BBOX['west']\n",
                "building_lats = np.random.uniform(COLOMBO_BBOX['south'], COLOMBO_BBOX['north'], n_buildings)\n",
                "\n",
                "buildings = gpd.GeoDataFrame({\n",
                "    'building_id': [f'B{i:04d}' for i in range(n_buildings)],\n",
                "    'geometry': [Point(lon, lat).buffer(0.0005) for lon, lat in zip(building_lons, building_lats)]\n",
                "}, crs='EPSG:4326')\n",
                "\n",
                "print(f\"‚úÖ Buildings: {len(buildings)} footprints\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize the study area\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "# Rainfall\n",
                "rainfall_cube.mean(dim='time').plot(ax=axes[0], cmap='Blues')\n",
                "axes[0].set_title('Mean Daily Rainfall (mm)')\n",
                "\n",
                "# Elevation\n",
                "elevation.plot(ax=axes[1], cmap='terrain')\n",
                "axes[1].set_title('Elevation (m)')\n",
                "\n",
                "# Admin and buildings\n",
                "admin_boundaries.plot(ax=axes[2], alpha=0.3, edgecolor='black')\n",
                "buildings.plot(ax=axes[2], color='red', markersize=1, alpha=0.5)\n",
                "axes[2].set_title('Admin Boundaries & Buildings')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 2. NumPy Array Operations\n",
                "\n",
                "Demonstrate array-based raster processing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get rainfall as numpy array\n",
                "rainfall_np = rainfall_cube.values\n",
                "print(f\"Rainfall array shape: {rainfall_np.shape} (days, lat, lon)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Operation 1: Create extreme rainfall mask (>50mm threshold)\n",
                "extreme_mask = raster_analysis.create_extreme_rainfall_mask(rainfall_np, threshold=50)\n",
                "print(f\"Extreme rainfall events (>50mm): {extreme_mask.sum()} occurrences\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Operation 2: Count extreme events per location\n",
                "extreme_counts = raster_analysis.count_extreme_events(rainfall_np, threshold=50)\n",
                "print(f\"Max extreme events at any location: {extreme_counts.max()}\")\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.imshow(extreme_counts, cmap='Reds', origin='lower',\n",
                "           extent=[COLOMBO_BBOX['west'], COLOMBO_BBOX['east'], \n",
                "                   COLOMBO_BBOX['south'], COLOMBO_BBOX['north']])\n",
                "plt.colorbar(label='Number of extreme rainfall days')\n",
                "plt.xlabel('Longitude')\n",
                "plt.ylabel('Latitude')\n",
                "plt.title('Extreme Rainfall Events (>50mm) in 2023')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Operation 3: Calculate 95th percentile rainfall\n",
                "p95_rainfall = raster_analysis.calculate_percentile_rainfall(rainfall_np, percentile=95)\n",
                "print(f\"95th percentile range: {p95_rainfall.min():.2f} - {p95_rainfall.max():.2f} mm\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Operation 4: Normalize for vulnerability calculation\n",
                "rainfall_norm = raster_analysis.normalize_array(p95_rainfall, method='minmax')\n",
                "elevation_norm = raster_analysis.normalize_array(elevation.values, method='minmax')\n",
                "\n",
                "print(f\"Normalized rainfall range: {rainfall_norm.min():.3f} - {rainfall_norm.max():.3f}\")\n",
                "print(f\"Normalized elevation range: {elevation_norm.min():.3f} - {elevation_norm.max():.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. PyTorch Tensor Operations\n",
                "\n",
                "GPU-aware processing with performance comparison."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "tensor_operations.print_gpu_info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert to tensor\n",
                "rainfall_tensor = tensor_operations.numpy_to_tensor(p95_rainfall, device='auto')\n",
                "print(f\"Tensor device: {rainfall_tensor.device}\")\n",
                "print(f\"Tensor shape: {rainfall_tensor.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply Gaussian convolution for spatial smoothing\n",
                "smoothed_tensor = tensor_operations.apply_gaussian_convolution(\n",
                "    rainfall_tensor, kernel_size=5, sigma=1.5\n",
                ")\n",
                "\n",
                "# Convert back to numpy for visualization\n",
                "smoothed = tensor_operations.tensor_to_numpy(smoothed_tensor)\n",
                "\n",
                "# Compare\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "axes[0].imshow(p95_rainfall, cmap='Blues', origin='lower')\n",
                "axes[0].set_title('Original 95th Percentile Rainfall')\n",
                "axes[1].imshow(smoothed, cmap='Blues', origin='lower')\n",
                "axes[1].set_title('Smoothed (PyTorch Gaussian Convolution)')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PERFORMANCE COMPARISON: NumPy vs PyTorch\n",
                "print(\"üî¨ Running performance comparison...\")\n",
                "print(\"(This measures Gaussian convolution speed)\\n\")\n",
                "\n",
                "perf_results = tensor_operations.compare_numpy_vs_torch(\n",
                "    p95_rainfall, kernel_size=5, sigma=1.5, num_iterations=10\n",
                ")\n",
                "\n",
                "print(\"=\" * 55)\n",
                "print(\"        PERFORMANCE COMPARISON RESULTS\")\n",
                "print(\"=\" * 55)\n",
                "print(f\"Array size:        {p95_rainfall.shape}\")\n",
                "print(f\"Operation:         5x5 Gaussian Convolution\")\n",
                "print(f\"Iterations:        10\")\n",
                "print(\"\")\n",
                "print(f\"NumPy (scipy):     {perf_results['numpy_time']*1000:.2f} ms ¬± {perf_results['numpy_std']*1000:.2f} ms\")\n",
                "print(f\"PyTorch ({perf_results['device']:6s}):  {perf_results['torch_time']*1000:.2f} ms ¬± {perf_results['torch_std']*1000:.2f} ms\")\n",
                "print(\"\")\n",
                "print(f\"Speedup:           {perf_results['speedup']:.2f}x\")\n",
                "print(\"=\" * 55)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. Vector Processing (GeoPandas/Shapely)\n",
                "\n",
                "At least 3 vector operations as required."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# OPERATION 1: Spatial Join - assign DS to each building\n",
                "buildings_joined = vector_analysis.spatial_join_buildings_to_admin(\n",
                "    buildings, admin_boundaries, admin_id_col='ds_id'\n",
                ")\n",
                "\n",
                "print(\"üìç OPERATION 1: Spatial Join\")\n",
                "print(f\"   Buildings with DS assignment: {len(buildings_joined)}\")\n",
                "print(buildings_joined[['building_id', 'ds_id']].head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# OPERATION 2: Building Density Calculation\n",
                "admin_with_density = vector_analysis.calculate_building_density(\n",
                "    buildings, admin_boundaries, admin_id_col='ds_id'\n",
                ")\n",
                "\n",
                "print(\"üìç OPERATION 2: Building Density Calculation\")\n",
                "print(admin_with_density[['ds_name', 'building_count', 'building_density']])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# OPERATION 3: Centroid calculation and area\n",
                "from shapely.geometry import LineString\n",
                "\n",
                "# Create sample roads\n",
                "roads = gpd.GeoDataFrame({\n",
                "    'road_id': ['R01', 'R02', 'R03'],\n",
                "    'highway': ['primary', 'secondary', 'primary'],\n",
                "    'geometry': [\n",
                "        LineString([(79.82, 6.9), (80.1, 6.9)]),\n",
                "        LineString([(79.9, 6.75), (79.9, 7.0)]),\n",
                "        LineString([(79.85, 6.85), (80.0, 6.95)])\n",
                "    ]\n",
                "}, crs='EPSG:4326')\n",
                "\n",
                "# Buffer analysis\n",
                "road_buffers = vector_analysis.create_road_buffers(\n",
                "    roads, buffer_distance=0.005, road_types=['primary', 'secondary']\n",
                ")\n",
                "\n",
                "print(\"üìç OPERATION 3: Buffer Analysis\")\n",
                "print(f\"   Created {len(road_buffers)} road buffers\")\n",
                "\n",
                "# Visualize\n",
                "fig, ax = plt.subplots(figsize=(10, 8))\n",
                "admin_with_density.plot(ax=ax, column='building_density', cmap='Reds', alpha=0.5, legend=True)\n",
                "road_buffers.plot(ax=ax, color='yellow', alpha=0.5)\n",
                "roads.plot(ax=ax, color='black', linewidth=2)\n",
                "buildings.plot(ax=ax, color='blue', markersize=1, alpha=0.3)\n",
                "ax.set_title('Building Density & Road Infrastructure')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Xarray Data Cubes\n",
                "\n",
                "Multi-temporal analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show data cube structure\n",
                "print(\"üìä Rainfall Data Cube Structure:\")\n",
                "print(rainfall_cube)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Monthly aggregation\n",
                "monthly_mean = rainfall_cube.groupby('time.month').mean(dim='time')\n",
                "\n",
                "# Plot monthly pattern\n",
                "monthly_spatial_mean = monthly_mean.mean(dim=['latitude', 'longitude'])\n",
                "\n",
                "plt.figure(figsize=(10, 4))\n",
                "monthly_spatial_mean.plot(marker='o')\n",
                "plt.xlabel('Month')\n",
                "plt.ylabel('Mean Daily Rainfall (mm)')\n",
                "plt.title('Seasonal Rainfall Pattern - Colombo District')\n",
                "plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
                "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Monsoon analysis (May-September)\n",
                "monsoon = rainfall_cube.sel(time=slice('2023-05-01', '2023-09-30'))\n",
                "non_monsoon = rainfall_cube.sel(time=slice('2023-01-01', '2023-04-30'))\n",
                "\n",
                "print(f\"Monsoon mean:     {monsoon.mean().values:.2f} mm/day\")\n",
                "print(f\"Non-monsoon mean: {non_monsoon.mean().values:.2f} mm/day\")\n",
                "print(f\"Monsoon ratio:    {monsoon.mean().values / non_monsoon.mean().values:.2f}x\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 6. Raster-Vector Integration\n",
                "\n",
                "Bidirectional integration as required."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save rasters for integration\n",
                "import rasterio\n",
                "from rasterio.transform import from_bounds\n",
                "\n",
                "bounds = (COLOMBO_BBOX['west'], COLOMBO_BBOX['south'], \n",
                "          COLOMBO_BBOX['east'], COLOMBO_BBOX['north'])\n",
                "\n",
                "# Save rainfall raster\n",
                "rainfall_path = OUTPUT_DIR / 'p95_rainfall.tif'\n",
                "with rasterio.open(\n",
                "    rainfall_path, 'w', driver='GTiff',\n",
                "    height=50, width=50, count=1, dtype='float32',\n",
                "    crs='EPSG:4326', transform=from_bounds(*bounds, 50, 50)\n",
                ") as dst:\n",
                "    dst.write(p95_rainfall.astype('float32'), 1)\n",
                "print(f\"‚úÖ Saved: {rainfall_path}\")\n",
                "\n",
                "# Save elevation raster\n",
                "elevation_path = OUTPUT_DIR / 'elevation.tif'\n",
                "with rasterio.open(\n",
                "    elevation_path, 'w', driver='GTiff',\n",
                "    height=50, width=50, count=1, dtype='float32',\n",
                "    crs='EPSG:4326', transform=from_bounds(*bounds, 50, 50)\n",
                ") as dst:\n",
                "    dst.write(elevation.values.astype('float32'), 1)\n",
                "print(f\"‚úÖ Saved: {elevation_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# RASTER ‚Üí VECTOR: Zonal Statistics\n",
                "admin_with_rainfall = integration.extract_zonal_statistics(\n",
                "    admin_boundaries, rainfall_path,\n",
                "    stats=['mean', 'max'], prefix='rainfall_'\n",
                ")\n",
                "\n",
                "admin_with_elev = integration.extract_zonal_statistics(\n",
                "    admin_with_rainfall, elevation_path,\n",
                "    stats=['mean', 'min'], prefix='elevation_'\n",
                ")\n",
                "\n",
                "print(\"üìç RASTER ‚Üí VECTOR: Zonal Statistics\")\n",
                "print(admin_with_elev[['ds_name', 'rainfall_mean', 'elevation_mean']])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VECTOR ‚Üí RASTER: Rasterize building density\n",
                "density_raster = integration.rasterize_vector(\n",
                "    admin_with_density,\n",
                "    value_column='building_density',\n",
                "    resolution=(-0.005, 0.005)\n",
                ")\n",
                "\n",
                "print(\"üìç VECTOR ‚Üí RASTER: Rasterized Building Density\")\n",
                "print(f\"   Shape: {density_raster.shape}\")\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "density_raster.plot(cmap='Oranges')\n",
                "plt.title('Rasterized Building Density')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Calculate Vulnerability Index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Combine all factors for vulnerability\n",
                "result = admin_with_density.merge(\n",
                "    admin_with_elev[['ds_id', 'rainfall_mean', 'rainfall_max', 'elevation_mean', 'elevation_min']],\n",
                "    on='ds_id'\n",
                ")\n",
                "\n",
                "# Normalize factors\n",
                "def normalize(series):\n",
                "    return (series - series.min()) / (series.max() - series.min() + 1e-10)\n",
                "\n",
                "rainfall_norm = normalize(result['rainfall_mean'])\n",
                "density_norm = normalize(result['building_density'])\n",
                "elev_norm = normalize(result['elevation_mean'])\n",
                "\n",
                "# Calculate vulnerability: V = 0.4*rainfall + 0.3*density + 0.3*(1-elevation)\n",
                "result['vulnerability_score'] = (\n",
                "    0.4 * rainfall_norm +\n",
                "    0.3 * density_norm +\n",
                "    0.3 * (1 - elev_norm)  # low elevation = high vulnerability\n",
                ")\n",
                "\n",
                "# Classify\n",
                "result['vulnerability_class'] = pd.cut(\n",
                "    result['vulnerability_score'],\n",
                "    bins=[0, 0.3, 0.5, 0.7, 1.0],\n",
                "    labels=['Low', 'Moderate', 'High', 'Extreme']\n",
                ")\n",
                "\n",
                "print(\"üìä VULNERABILITY ASSESSMENT RESULTS\")\n",
                "print(\"=\" * 60)\n",
                "print(result[['ds_name', 'rainfall_mean', 'building_density', 'elevation_mean', 'vulnerability_score', 'vulnerability_class']])\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 7. Visualization\n",
                "\n",
                "Final maps and outputs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add required columns for visualization\n",
                "result['id'] = result['ds_id']\n",
                "\n",
                "# Create interactive vulnerability map\n",
                "vuln_map = visualization.create_vulnerability_map(\n",
                "    result,\n",
                "    value_column='vulnerability_score',\n",
                "    title='Flood Vulnerability Score'\n",
                ")\n",
                "\n",
                "# Display\n",
                "vuln_map"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save interactive map\n",
                "vuln_map.save(OUTPUT_DIR / 'vulnerability_map.html')\n",
                "print(f\"‚úÖ Saved: {OUTPUT_DIR / 'vulnerability_map.html'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create ranking chart\n",
                "ranking_chart = visualization.create_vulnerability_ranking_chart(\n",
                "    result,\n",
                "    name_column='ds_name',\n",
                "    value_column='vulnerability_score',\n",
                "    top_n=10,\n",
                "    title='Vulnerability Ranking - Colombo District'\n",
                ")\n",
                "ranking_chart.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create static map for report\n",
                "fig = visualization.create_static_map(\n",
                "    result,\n",
                "    value_column='vulnerability_score',\n",
                "    title='Flood Vulnerability Assessment - Colombo District, Sri Lanka',\n",
                "    cmap='YlOrRd'\n",
                ")\n",
                "\n",
                "fig.savefig(OUTPUT_DIR / 'vulnerability_map.png', dpi=150, bbox_inches='tight')\n",
                "print(f\"‚úÖ Saved: {OUTPUT_DIR / 'vulnerability_map.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Summary\n",
                "\n",
                "This notebook demonstrated all required technical components:\n",
                "\n",
                "| Component | Implementation |\n",
                "|-----------|----------------|\n",
                "| **NumPy Arrays** | Masking, normalization, percentile calculation |\n",
                "| **PyTorch Tensors** | Gaussian convolution, GPU-awareness, performance comparison |\n",
                "| **Vector Processing** | Spatial join, density calculation, buffer analysis (3+ ops) |\n",
                "| **Xarray Data Cubes** | Temporal slicing, aggregation, groupby operations |\n",
                "| **Raster-Vector Integration** | Zonal statistics (R‚ÜíV), rasterization (V‚ÜíR) |\n",
                "\n",
                "**Vulnerability Formula:**\n",
                "\n",
                "$$V = 0.4 \\times Rainfall_{norm} + 0.3 \\times BuildingDensity_{norm} + 0.3 \\times (1 - Elevation_{norm})$$"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}